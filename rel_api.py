# encoding=utf-8
# authorï¼š s0mE
# subjectï¼š ä½¿ç”¨åœ¨çº¿ API è¿›è¡Œäººç‰©å…³ç³»æå–ï¼ˆæ”¯æŒ OpenAIã€æ™ºè°±ã€DeepSeek ç­‰ï¼‰
# dateï¼š 2024
import argparse
import os
import re
import json
import time
from collections import defaultdict
from tqdm import tqdm
import numpy as np
import networkx as nx
import matplotlib
# åœ¨ CI ç¯å¢ƒä¸­ä½¿ç”¨éäº¤äº’å¼åç«¯
if os.getenv('CI') == 'true' or os.getenv('DISPLAY') is None:
    matplotlib.use('Agg')
import matplotlib.pyplot as plt
import pandas as pd

# è®¾ç½®ä¸­æ–‡å­—ä½“
import matplotlib.font_manager as fm

chinese_fonts = ['SimHei', 'Microsoft YaHei', 'WenQuanYi Micro Hei', 'WenQuanYi Zen Hei', 
                 'Noto Sans CJK SC', 'Source Han Sans CN', 'Droid Sans Fallback', 'DejaVu Sans']
available_fonts = [f.name for f in fm.fontManager.ttflist]

font_found = None
for font in chinese_fonts:
    if font in available_fonts:
        font_found = font
        break

if font_found:
    plt.rcParams["font.sans-serif"] = [font_found] + plt.rcParams["font.sans-serif"]
else:
    plt.rcParams["font.sans-serif"] = ["DejaVu Sans"] + plt.rcParams["font.sans-serif"]
    print("âš ï¸ Warning: No Chinese font found, Chinese characters may display as squares")

plt.rcParams["axes.unicode_minus"] = False


class LLMAPI:
    """ç»Ÿä¸€çš„ LLM API æ¥å£"""
    
    def __init__(self, provider='openai', api_key=None, base_url=None):
        """
        Args:
            provider: API æä¾›å•† ('openai', 'zhipu', 'deepseek', 'moonshot', 'qwen')
            api_key: API å¯†é’¥
            base_url: API åŸºç¡€ URLï¼ˆå¯é€‰ï¼Œç”¨äºè‡ªå®šä¹‰ç«¯ç‚¹ï¼‰
        """
        self.provider = provider.lower()
        self.api_key = api_key or os.getenv(f'{provider.upper()}_API_KEY') or os.getenv('API_KEY')
        self.base_url = base_url
        
        if not self.api_key:
            raise ValueError(f"éœ€è¦è®¾ç½® API å¯†é’¥ï¼Œé€šè¿‡å‚æ•°æˆ–ç¯å¢ƒå˜é‡ {provider.upper()}_API_KEY")
        
        # æ ¹æ®æä¾›å•†è®¾ç½®é»˜è®¤ base_url
        if not self.base_url:
            if self.provider == 'openai':
                self.base_url = 'https://api.openai.com/v1'
            elif self.provider == 'zhipu':
                self.base_url = 'https://open.bigmodel.cn/api/paas/v4'
            elif self.provider == 'deepseek':
                self.base_url = 'https://api.deepseek.com/v1'
            elif self.provider == 'moonshot':
                self.base_url = 'https://api.moonshot.cn/v1'
            elif self.provider == 'qwen':
                self.base_url = 'https://dashscope.aliyuncs.com/api/v1'
        
        # è®¾ç½®æ¨¡å‹åç§°
        self.model_map = {
            'openai': 'gpt-3.5-turbo',
            'zhipu': 'glm-4',
            'deepseek': 'deepseek-chat',
            'moonshot': 'moonshot-v1-8k',
            'qwen': 'qwen-turbo'
        }
        self.model = self.model_map.get(self.provider, 'gpt-3.5-turbo')
    
    def call_api(self, prompt, max_tokens=2000, temperature=0.3):
        """è°ƒç”¨ API"""
        import requests
        
        headers = {
            'Content-Type': 'application/json',
        }
        
        if self.provider == 'openai':
            headers['Authorization'] = f'Bearer {self.api_key}'
            url = f'{self.base_url}/chat/completions'
            data = {
                'model': self.model,
                'messages': [{'role': 'user', 'content': prompt}],
                'temperature': temperature,
                'max_tokens': max_tokens
            }
        elif self.provider == 'zhipu':
            headers['Authorization'] = f'Bearer {self.api_key}'
            url = f'{self.base_url}/chat/completions'
            data = {
                'model': self.model,
                'messages': [{'role': 'user', 'content': prompt}],
                'temperature': temperature,
                'max_tokens': max_tokens
            }
        elif self.provider == 'deepseek':
            headers['Authorization'] = f'Bearer {self.api_key}'
            url = f'{self.base_url}/chat/completions'
            data = {
                'model': self.model,
                'messages': [{'role': 'user', 'content': prompt}],
                'temperature': temperature,
                'max_tokens': max_tokens
            }
        elif self.provider == 'moonshot':
            headers['Authorization'] = f'Bearer {self.api_key}'
            url = f'{self.base_url}/chat/completions'
            data = {
                'model': self.model,
                'messages': [{'role': 'user', 'content': prompt}],
                'temperature': temperature,
                'max_tokens': max_tokens
            }
        elif self.provider == 'qwen':
            headers['Authorization'] = f'Bearer {self.api_key}'
            url = f'{self.base_url}/services/aigc/text-generation/generation'
            data = {
                'model': self.model,
                'input': {'messages': [{'role': 'user', 'content': prompt}]},
                'parameters': {
                    'temperature': temperature,
                    'max_tokens': max_tokens
                }
            }
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„æä¾›å•†: {self.provider}")
        
        try:
            response = requests.post(url, headers=headers, json=data, timeout=60)
            response.raise_for_status()
            result = response.json()
            
            # è§£æå“åº”
            if self.provider == 'qwen':
                return result.get('output', {}).get('text', '')
            else:
                return result.get('choices', [{}])[0].get('message', {}).get('content', '')
        except requests.exceptions.RequestException as e:
            print(f"âŒ API è°ƒç”¨å¤±è´¥: {e}")
            if hasattr(e, 'response') and e.response is not None:
                print(f"   å“åº”å†…å®¹: {e.response.text}")
            raise


def extract_relationships_with_llm(file_path, api_provider='openai', api_key=None, 
                                   batch_size=10, max_length=500):
    """
    ä½¿ç”¨å¤§è¯­è¨€æ¨¡å‹ API ä»å°è¯´æ–‡æœ¬ä¸­æå–äººç‰©å…³ç³»
    
    Args:
        file_path: å°è¯´æ–‡ä»¶è·¯å¾„
        api_provider: API æä¾›å•†
        api_key: API å¯†é’¥
        batch_size: æ‰¹å¤„ç†å¤§å°ï¼ˆæ¯æ‰¹å¤„ç†çš„å¥å­æ•°ï¼‰
        max_length: æœ€å¤§æ–‡æœ¬é•¿åº¦
    
    Returns:
        relationships: å…³ç³»åˆ—è¡¨ï¼Œæ ¼å¼ä¸º [(person1, relation, person2, confidence), ...]
        entities: å®ä½“åˆ—è¡¨
    """
    # åˆå§‹åŒ– API
    try:
        llm = LLMAPI(provider=api_provider, api_key=api_key)
        print(f"âœ… å·²è¿æ¥åˆ° {api_provider.upper()} API")
    except Exception as e:
        print(f"âŒ API åˆå§‹åŒ–å¤±è´¥: {e}")
        raise
    
    # è¯»å–æ–‡æœ¬æ–‡ä»¶
    print("ğŸ“– æ­£åœ¨è¯»å–æ–‡æœ¬æ–‡ä»¶...")
    try:
        with open(file_path, "r", encoding="utf-8") as f:
            lines = f.readlines()
    except UnicodeDecodeError:
        with open(file_path, "r", encoding="gbk") as f:
            lines = f.readlines()
    
    # è¿‡æ»¤å’Œæ¸…ç†æ–‡æœ¬
    lines = [line.strip() for line in lines if len(line.strip()) > 10]
    
    # æ„å»ºæç¤ºè¯æ¨¡æ¿
    prompt_template = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å°è¯´åˆ†æåŠ©æ‰‹ã€‚è¯·ä»ä»¥ä¸‹æ–‡æœ¬ä¸­æå–äººç‰©å…³ç³»ã€‚

è¦æ±‚ï¼š
1. è¯†åˆ«æ–‡æœ¬ä¸­å‡ºç°çš„æ‰€æœ‰äººç‰©å§“å
2. æå–äººç‰©ä¹‹é—´çš„å…³ç³»ï¼ˆå¦‚ï¼šçˆ¶å­ã€æœ‹å‹ã€æ‹äººã€åŒäº‹ã€æ•Œäººã€å¸ˆç”Ÿç­‰ï¼‰
3. å¦‚æœå…³ç³»ä¸æ˜ç¡®ï¼Œä½¿ç”¨"ç›¸å…³"ä½œä¸ºå…³ç³»ç±»å‹

è¾“å‡ºæ ¼å¼ä¸º JSON æ•°ç»„ï¼Œæ¯ä¸ªå…ƒç´ æ ¼å¼å¦‚ä¸‹ï¼š
{
  "person1": "äººç‰©1",
  "relation": "å…³ç³»ç±»å‹",
  "person2": "äººç‰©2"
}

æ–‡æœ¬å†…å®¹ï¼š
{text}

è¯·åªè¿”å› JSON æ•°ç»„ï¼Œä¸è¦åŒ…å«å…¶ä»–è§£é‡Šæ–‡å­—ã€‚å¦‚æœæ–‡æœ¬ä¸­æ²¡æœ‰äººç‰©å…³ç³»ï¼Œè¿”å›ç©ºæ•°ç»„ []ã€‚"""

    relationships = []
    entities = set()
    
    print("ğŸ” æ­£åœ¨ä½¿ç”¨ LLM API æå–äººç‰©å…³ç³»...")
    
    # åˆ†æ‰¹å¤„ç†æ–‡æœ¬
    batch_texts = []
    current_batch = ""
    
    for i, line in enumerate(tqdm(lines, desc="Processing")):
        # æ¸…ç†æ–‡æœ¬
        line = re.sub(r'\s+', '', line)
        if len(line) < 10:
            continue
        
        # ç´¯ç§¯æ–‡æœ¬
        if len(current_batch) + len(line) < max_length:
            current_batch += line + "ã€‚"
        else:
            if current_batch:
                batch_texts.append(current_batch)
                current_batch = line + "ã€‚"
            else:
                # å¦‚æœå•è¡Œå¤ªé•¿ï¼Œæˆªæ–­
                current_batch = line[:max_length] + "ã€‚"
        
        # å½“è¾¾åˆ°æ‰¹å¤„ç†å¤§å°æ—¶ï¼Œè¿›è¡ŒæŠ½å–
        if len(batch_texts) >= batch_size:
            try:
                # åˆå¹¶æ‰¹æ¬¡æ–‡æœ¬
                combined_text = "\n".join(batch_texts)
                prompt = prompt_template.format(text=combined_text[:2000])  # é™åˆ¶æ€»é•¿åº¦
                
                # è°ƒç”¨ API
                response = llm.call_api(prompt, max_tokens=2000, temperature=0.3)
                
                # è§£æå“åº”
                try:
                    # å°è¯•æå– JSON
                    json_match = re.search(r'\[.*\]', response, re.DOTALL)
                    if json_match:
                        rel_data = json.loads(json_match.group())
                    else:
                        # å¦‚æœæ²¡æœ‰æ‰¾åˆ° JSONï¼Œå°è¯•ç›´æ¥è§£æ
                        rel_data = json.loads(response)
                    
                    # å¤„ç†æå–çš„å…³ç³»
                    for item in rel_data:
                        if isinstance(item, dict) and 'person1' in item and 'person2' in item:
                            person1 = item.get('person1', '').strip()
                            person2 = item.get('person2', '').strip()
                            relation = item.get('relation', 'ç›¸å…³').strip()
                            
                            if person1 and person2 and person1 != person2:
                                entities.add(person1)
                                entities.add(person2)
                                relationships.append((
                                    person1,
                                    relation,
                                    person2,
                                    0.8  # é»˜è®¤ç½®ä¿¡åº¦
                                ))
                except json.JSONDecodeError as e:
                    print(f"âš ï¸ JSON è§£æå¤±è´¥: {e}")
                    print(f"   å“åº”å†…å®¹: {response[:200]}")
                
                batch_texts = []
                current_batch = ""
                
                # é¿å… API é™æµ
                time.sleep(0.5)
                
            except Exception as e:
                print(f"âš ï¸ å¤„ç†æ‰¹æ¬¡æ—¶å‡ºé”™: {e}")
                batch_texts = []
                current_batch = ""
                continue
    
    # å¤„ç†å‰©ä½™æ–‡æœ¬
    if current_batch:
        batch_texts.append(current_batch)
    
    if batch_texts:
        try:
            combined_text = "\n".join(batch_texts)
            prompt = prompt_template.format(text=combined_text[:2000])
            response = llm.call_api(prompt, max_tokens=2000, temperature=0.3)
            
            try:
                json_match = re.search(r'\[.*\]', response, re.DOTALL)
                if json_match:
                    rel_data = json.loads(json_match.group())
                else:
                    rel_data = json.loads(response)
                
                for item in rel_data:
                    if isinstance(item, dict) and 'person1' in item and 'person2' in item:
                        person1 = item.get('person1', '').strip()
                        person2 = item.get('person2', '').strip()
                        relation = item.get('relation', 'ç›¸å…³').strip()
                        
                        if person1 and person2 and person1 != person2:
                            entities.add(person1)
                            entities.add(person2)
                            relationships.append((
                                person1,
                                relation,
                                person2,
                                0.8
                            ))
            except json.JSONDecodeError as e:
                print(f"âš ï¸ JSON è§£æå¤±è´¥: {e}")
        except Exception as e:
            print(f"âš ï¸ å¤„ç†æœ€åæ‰¹æ¬¡æ—¶å‡ºé”™: {e}")
    
    print(f"âœ… æå–å®Œæˆ: å‘ç° {len(entities)} ä¸ªäººç‰©ï¼Œ{len(relationships)} ä¸ªå…³ç³»")
    return relationships, list(entities)


# å¤ç”¨åŸæœ‰çš„å…³ç³»å›¾ç»˜åˆ¶å’Œ Excel å¯¼å‡ºå‡½æ•°
def build_relationship_graph(relationships, entities=None):
    """æ„å»ºäººç‰©å…³ç³»å›¾"""
    G = nx.Graph()
    rel_dict = defaultdict(list)
    
    if entities:
        for entity in entities:
            G.add_node(entity)
    
    for person1, relation, person2, confidence in relationships:
        if person1 and person2 and person1 != person2:
            G.add_node(person1)
            G.add_node(person2)
            G.add_edge(person1, person2, weight=1.0, relation=relation, confidence=confidence)
            rel_dict[(person1, person2)].append((relation, confidence))
    
    return G, dict(rel_dict)


def plot_relationship_graph(G, relationships, save_path=None, book_name=None):
    """ç»˜åˆ¶äººç‰©å…³ç³»å›¾"""
    if not G.nodes():
        print("âš ï¸ å›¾ä¸­æ²¡æœ‰èŠ‚ç‚¹ï¼Œæ— æ³•ç»˜åˆ¶")
        return
    
    degrees = dict(G.degree())
    
    if nx.is_connected(G):
        main_G = G
    else:
        components = list(nx.connected_components(G))
        main_component = max(components, key=len)
        main_G = G.subgraph(main_component).copy()
        print(f"ğŸ“Š ä¸»è¦å­å›¾åŒ…å« {len(main_component)} ä¸ªèŠ‚ç‚¹ï¼ˆå…± {len(G.nodes())} ä¸ªèŠ‚ç‚¹ï¼‰")
    
    node_sizes = [degrees.get(node, 1) * 500 for node in main_G.nodes()]
    node_sizes = [max(s, 100) for s in node_sizes]
    
    edge_weights = [G[u][v].get('weight', 1.0) for u, v in main_G.edges()]
    if edge_weights:
        max_weight = max(edge_weights)
        edge_weights = [w * 2.0 / max_weight for w in edge_weights]
    
    num_nodes = len(main_G.nodes())
    if num_nodes > 50:
        figsize = (32, 24)
        font_size = 6
    elif num_nodes > 30:
        figsize = (24, 20)
        font_size = 8
    else:
        figsize = (18, 15)
        font_size = 10
    
    plt.figure(figsize=figsize)
    pos = nx.spring_layout(main_G, k=2, iterations=50)
    
    nx.draw_networkx_nodes(main_G, pos, node_size=node_sizes, 
                          node_color='lightblue', alpha=0.7, 
                          edgecolors='black', linewidths=0.5)
    nx.draw_networkx_edges(main_G, pos, width=edge_weights, 
                          alpha=0.5, edge_color='gray')
    
    labels = {node: node for node in main_G.nodes()}
    nx.draw_networkx_labels(main_G, pos, labels, font_size=font_size,
                           font_family='sans-serif',
                           bbox=dict(boxstyle='round,pad=0.3', 
                                    facecolor='white', 
                                    edgecolor='none', alpha=0.7))
    
    plt.title(f"äººç‰©å…³ç³»å›¾ - {book_name or 'æœªçŸ¥'} (å…±{num_nodes}ä¸ªäººç‰©)", 
              fontsize=14, pad=20)
    plt.axis('off')
    
    if save_path is None:
        save_path = "output"
    os.makedirs(save_path, exist_ok=True)
    
    if book_name:
        safe_book_name = re.sub(r'[<>:"/\\|?*]', '_', book_name)
        filename = os.path.join(save_path, f"{safe_book_name}_api_relationship.png")
    else:
        filename = os.path.join(save_path, "api_relationship.png")
    
    plt.savefig(filename, dpi=150, bbox_inches='tight', 
                facecolor='white', edgecolor='none')
    print(f"âœ… å·²ä¿å­˜å…³ç³»å›¾: {filename}")
    plt.close()


def export_to_excel(relationships, entities, file_path, book_name=None):
    """å¯¼å‡ºäººç‰©å…³ç³»åˆ° Excel æ–‡ä»¶"""
    rel_data = []
    for person1, relation, person2, confidence in relationships:
        rel_data.append({
            'äººç‰©1': person1,
            'å…³ç³»': relation if relation else 'ç›¸å…³',
            'äººç‰©2': person2,
            'ç½®ä¿¡åº¦': f"{confidence:.4f}" if confidence > 0 else "N/A"
        })
    
    entity_data = []
    entity_counts = defaultdict(int)
    for person1, _, person2, _ in relationships:
        entity_counts[person1] += 1
        entity_counts[person2] += 1
    
    for entity in entities:
        entity_data.append({
            'äººç‰©': entity,
            'å…³ç³»æ•°é‡': entity_counts.get(entity, 0)
        })
    entity_data.sort(key=lambda x: x['å…³ç³»æ•°é‡'], reverse=True)
    
    relation_type_counts = defaultdict(int)
    for _, relation, _, _ in relationships:
        rel_type = relation if relation else 'ç›¸å…³'
        relation_type_counts[rel_type] += 1
    
    rel_type_data = []
    for rel_type, count in sorted(relation_type_counts.items(), 
                                  key=lambda x: x[1], reverse=True):
        rel_type_data.append({
            'å…³ç³»ç±»å‹': rel_type,
            'å‡ºç°æ¬¡æ•°': count
        })
    
    with pd.ExcelWriter(file_path, engine='openpyxl') as writer:
        if rel_data:
            df_rel = pd.DataFrame(rel_data)
            df_rel.to_excel(writer, sheet_name='å…³ç³»è¯¦æƒ…', index=False)
        
        if entity_data:
            df_entity = pd.DataFrame(entity_data)
            df_entity.to_excel(writer, sheet_name='äººç‰©ç»Ÿè®¡', index=False)
        
        if rel_type_data:
            df_rel_type = pd.DataFrame(rel_type_data)
            df_rel_type.to_excel(writer, sheet_name='å…³ç³»ç±»å‹ç»Ÿè®¡', index=False)
    
    print(f"âœ… å·²å¯¼å‡º Excel æ–‡ä»¶: {file_path}")


def sanitize_filename(filename):
    """æ¸…ç†æ–‡ä»¶å"""
    filename = re.sub(r'[<>:"/\\|?*]', '_', filename)
    filename = filename.strip(' .')
    if len(filename) > 100:
        filename = filename[:100]
    return filename


def main():
    parser = argparse.ArgumentParser(description="ä½¿ç”¨åœ¨çº¿ API æå–å°è¯´äººç‰©å…³ç³»")
    parser.add_argument("--book", default="å†¬æ—¥é‡ç°", type=str,
                       help="ä¹¦çš„åå­—ï¼Œä¸å¸¦åç¼€")
    parser.add_argument("--provider", default="openai", type=str,
                       choices=['openai', 'zhipu', 'deepseek', 'moonshot', 'qwen'],
                       help="API æä¾›å•†")
    parser.add_argument("--api_key", type=str, default=None,
                       help="API å¯†é’¥ï¼ˆä¹Ÿå¯é€šè¿‡ç¯å¢ƒå˜é‡è®¾ç½®ï¼‰")
    parser.add_argument("--base_url", type=str, default=None,
                       help="è‡ªå®šä¹‰ API åŸºç¡€ URL")
    parser.add_argument("--batch_size", type=int, default=10,
                       help="æ‰¹å¤„ç†å¤§å°ï¼ˆæ¯æ‰¹å¤„ç†çš„å¥å­æ•°ï¼‰")
    parser.add_argument("--max_length", type=int, default=500,
                       help="æœ€å¤§æ–‡æœ¬é•¿åº¦")
    parser.add_argument("--output", default="output", type=str,
                       help="è¾“å‡ºç›®å½•")
    
    args = parser.parse_args()
    
    # æ–‡ä»¶è·¯å¾„
    fp = f"book/{args.book}.txt"
    if not os.path.exists(fp):
        print(f"âŒ é”™è¯¯: æ–‡ä»¶ä¸å­˜åœ¨: {fp}")
        return
    
    print(f"=====+++=== ä½¿ç”¨ {args.provider.upper()} API åˆ†æ: {args.book} ===+++=====")
    
    # æå–å…³ç³»
    try:
        relationships, entities = extract_relationships_with_llm(
            fp, 
            api_provider=args.provider,
            api_key=args.api_key,
            batch_size=args.batch_size,
            max_length=args.max_length
        )
        
        if not relationships:
            print("âš ï¸ æœªæå–åˆ°ä»»ä½•å…³ç³»ï¼Œå¯èƒ½éœ€è¦è°ƒæ•´å‚æ•°æˆ–æ£€æŸ¥ API é…ç½®")
            return
        
        # æ„å»ºå…³ç³»å›¾
        print("ğŸ“Š æ­£åœ¨æ„å»ºå…³ç³»å›¾...")
        G, rel_dict = build_relationship_graph(relationships, entities)
        
        # ç»˜åˆ¶å…³ç³»å›¾
        print("ğŸ¨ æ­£åœ¨ç»˜åˆ¶å…³ç³»å›¾...")
        os.makedirs(args.output, exist_ok=True)
        plot_relationship_graph(G, relationships, 
                               save_path=args.output, 
                               book_name=args.book)
        
        # å¯¼å‡º Excel
        print("ğŸ“ æ­£åœ¨å¯¼å‡º Excel æ–‡ä»¶...")
        excel_path = os.path.join(args.output, 
                                 f"{sanitize_filename(args.book)}_äººç‰©å…³ç³»_api.xlsx")
        export_to_excel(relationships, entities, excel_path, book_name=args.book)
        
        print("="*50)
        print("âœ… å¤„ç†å®Œæˆï¼")
        print(f"   - æå–åˆ° {len(entities)} ä¸ªäººç‰©")
        print(f"   - æå–åˆ° {len(relationships)} ä¸ªå…³ç³»")
        print(f"   - å…³ç³»å›¾å·²ä¿å­˜åˆ°: {args.output}")
        print(f"   - Excel æ–‡ä»¶å·²ä¿å­˜åˆ°: {excel_path}")
        print("="*50)
        
    except Exception as e:
        print(f"âŒ å¤„ç†è¿‡ç¨‹ä¸­å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()

