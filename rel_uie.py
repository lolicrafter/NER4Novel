# encoding=utf-8
# authorï¼š s0mE
# subjectï¼š ä½¿ç”¨ PaddleNLP UIE è¿›è¡Œäººç‰©å…³ç³»æå–
# dateï¼š 2024
import argparse
import os
import re
from collections import defaultdict
from tqdm import tqdm
import numpy as np
import networkx as nx
import matplotlib
# åœ¨ CI ç¯å¢ƒä¸­ä½¿ç”¨éäº¤äº’å¼åç«¯
if os.getenv('CI') == 'true' or os.getenv('DISPLAY') is None:
    matplotlib.use('Agg')
import matplotlib.pyplot as plt
import pandas as pd

try:
    from paddlenlp import Taskflow
    UIE_AVAILABLE = True
except ImportError:
    UIE_AVAILABLE = False
    print("âš ï¸ è­¦å‘Š: PaddleNLP æœªå®‰è£…ï¼Œè¯·è¿è¡Œ: pip install paddlenlp")

# è®¾ç½®ä¸­æ–‡å­—ä½“
import matplotlib.font_manager as fm

chinese_fonts = ['SimHei', 'Microsoft YaHei', 'WenQuanYi Micro Hei', 'WenQuanYi Zen Hei', 
                 'Noto Sans CJK SC', 'Source Han Sans CN', 'Droid Sans Fallback', 'DejaVu Sans']
available_fonts = [f.name for f in fm.fontManager.ttflist]

font_found = None
for font in chinese_fonts:
    if font in available_fonts:
        font_found = font
        break

if font_found:
    plt.rcParams["font.sans-serif"] = [font_found] + plt.rcParams["font.sans-serif"]
else:
    plt.rcParams["font.sans-serif"] = ["DejaVu Sans"] + plt.rcParams["font.sans-serif"]
    print("âš ï¸ Warning: No Chinese font found, Chinese characters may display as squares")

plt.rcParams["axes.unicode_minus"] = False


def extract_relationships_with_uie(file_path, schema=None, batch_size=32, max_length=512):
    """
    ä½¿ç”¨ PaddleNLP UIE ä»å°è¯´æ–‡æœ¬ä¸­æå–äººç‰©å…³ç³»
    
    Args:
        file_path: å°è¯´æ–‡ä»¶è·¯å¾„
        schema: UIE çš„æŠ½å–æ¨¡å¼ï¼Œé»˜è®¤ä¸ºäººç‰©å…³ç³»æŠ½å–
        batch_size: æ‰¹å¤„ç†å¤§å°
        max_length: æœ€å¤§æ–‡æœ¬é•¿åº¦
    
    Returns:
        relationships: å…³ç³»åˆ—è¡¨ï¼Œæ ¼å¼ä¸º [(person1, relation, person2, confidence), ...]
        entities: å®ä½“åˆ—è¡¨
    """
    if not UIE_AVAILABLE:
        raise ImportError("PaddleNLP æœªå®‰è£…ï¼Œè¯·è¿è¡Œ: pip install paddlenlp")
    
    # é»˜è®¤ schemaï¼šæŠ½å–äººç‰©åŠå…¶å…³ç³»
    # UIE æ”¯æŒå¤šç§ schema æ ¼å¼ï¼Œè¿™é‡Œä½¿ç”¨å…³ç³»æŠ½å–æ¨¡å¼
    if schema is None:
        # æ–¹å¼1ï¼šå…³ç³»æŠ½å–æ¨¡å¼ - ç›´æ¥å®šä¹‰å…³ç³»ä¸‰å…ƒç»„
        schema = [
            {'äººç‰©': ['å…³ç³»']},  # æŠ½å– (äººç‰©, å…³ç³») å¯¹
            {'äººç‰©': ['äººç‰©']}   # æŠ½å– (äººç‰©, äººç‰©) å¯¹ï¼Œç”¨äºå…±ç°å…³ç³»
        ]
    
    # åˆå§‹åŒ– UIE æ¨¡å‹
    # æ”¯æŒé€šè¿‡ç¯å¢ƒå˜é‡é€‰æ‹©æ¨¡å‹ï¼ˆåœ¨ CI ç¯å¢ƒä¸­å¯ä»¥ä½¿ç”¨æ›´å°çš„æ¨¡å‹ï¼‰
    model_name = os.getenv('UIE_MODEL', 'uie-base')  # é»˜è®¤ä½¿ç”¨ uie-base
    # åœ¨ CI ç¯å¢ƒä¸­ï¼Œå¦‚æœæ²¡æœ‰ GPUï¼Œä½¿ç”¨æ›´å°çš„æ¨¡å‹
    if os.getenv('CI') == 'true':
        # uie-nano æ˜¯æœ€å°çš„æ¨¡å‹ï¼Œé€‚åˆ CI ç¯å¢ƒ
        # uie-tiny æ˜¯è¾ƒå°çš„æ¨¡å‹ï¼Œé€‚åˆèµ„æºå—é™ç¯å¢ƒ
        # å¦‚æœç¯å¢ƒå˜é‡æœªè®¾ç½®ï¼Œåœ¨ CI ä¸­ä½¿ç”¨ uie-tiny
        if model_name == 'uie-base':
            model_name = 'uie-tiny'  # CI ç¯å¢ƒé»˜è®¤ä½¿ç”¨è¾ƒå°æ¨¡å‹
            print("âš ï¸ CI ç¯å¢ƒæ£€æµ‹åˆ°ï¼Œä½¿ç”¨è½»é‡çº§æ¨¡å‹ uie-tinyï¼ˆå¯é€šè¿‡ UIE_MODEL ç¯å¢ƒå˜é‡è¦†ç›–ï¼‰")
    
    print(f"ğŸ“¦ æ­£åœ¨åŠ è½½ PaddleNLP UIE æ¨¡å‹: {model_name}...")
    print("   ğŸ’¡ æç¤º: é¦–æ¬¡è¿è¡Œä¼šä¸‹è½½æ¨¡å‹æ–‡ä»¶ï¼ˆå¯èƒ½éœ€è¦å‡ åˆ†é’Ÿï¼‰")
    
    try:
        # å°è¯•ä½¿ç”¨æŒ‡å®šçš„æ¨¡å‹
        if model_name in ['uie-base', 'uie-medium', 'uie-mini', 'uie-micro', 'uie-nano', 'uie-tiny']:
            ie = Taskflow('information_extraction', 
                          schema=schema,
                          task_path=model_name,
                          batch_size=batch_size,
                          max_length=max_length)
        else:
            # å¦‚æœæŒ‡å®šäº†è‡ªå®šä¹‰è·¯å¾„æˆ–å…¶ä»–æ¨¡å‹å
            ie = Taskflow('information_extraction', 
                          schema=schema,
                          task_path=model_name,
                          batch_size=batch_size,
                          max_length=max_length)
    except Exception as e:
        print(f"âš ï¸ æ¨¡å‹ {model_name} åŠ è½½å¤±è´¥: {e}")
        print("   å°è¯•ä½¿ç”¨é»˜è®¤æ¨¡å‹é…ç½®...")
        # å¦‚æœæŒ‡å®šæ¨¡å‹è·¯å¾„å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤æ¨¡å‹
        try:
            ie = Taskflow('information_extraction', 
                          schema=schema,
                          batch_size=batch_size,
                          max_length=max_length)
        except Exception as e2:
            print(f"âŒ é»˜è®¤æ¨¡å‹åŠ è½½ä¹Ÿå¤±è´¥: {e2}")
            raise
    
    # è¯»å–æ–‡æœ¬æ–‡ä»¶
    print("ğŸ“– æ­£åœ¨è¯»å–æ–‡æœ¬æ–‡ä»¶...")
    try:
        with open(file_path, "r", encoding="utf-8") as f:
            lines = f.readlines()
    except UnicodeDecodeError:
        with open(file_path, "r", encoding="gbk") as f:
            lines = f.readlines()
    
    # è¿‡æ»¤ç©ºè¡Œå’Œè¿‡çŸ­çš„è¡Œ
    lines = [line.strip() for line in lines if len(line.strip()) > 10]
    
    relationships = []
    entities = set()
    all_results = []
    
    print("ğŸ” æ­£åœ¨ä½¿ç”¨ UIE æå–äººç‰©å…³ç³»...")
    # åˆ†æ‰¹å¤„ç†æ–‡æœ¬
    batch_texts = []
    for i, line in enumerate(tqdm(lines, desc="Processing")):
        # æ¸…ç†æ–‡æœ¬
        line = re.sub(r'\s+', '', line)
        if len(line) < 10:
            continue
        
        batch_texts.append(line)
        
        # å½“è¾¾åˆ°æ‰¹å¤„ç†å¤§å°æ—¶ï¼Œè¿›è¡ŒæŠ½å–
        if len(batch_texts) >= batch_size:
            try:
                results = ie(batch_texts)
                all_results.extend(results)
                batch_texts = []
            except Exception as e:
                print(f"âš ï¸ å¤„ç†æ‰¹æ¬¡æ—¶å‡ºé”™: {e}")
                batch_texts = []
                continue
    
    # å¤„ç†å‰©ä½™çš„æ–‡æœ¬
    if batch_texts:
        try:
            results = ie(batch_texts)
            all_results.extend(results)
        except Exception as e:
            print(f"âš ï¸ å¤„ç†æœ€åæ‰¹æ¬¡æ—¶å‡ºé”™: {e}")
    
    # è§£æç»“æœ
    print("ğŸ“Š æ­£åœ¨è§£ææŠ½å–ç»“æœ...")
    for result in tqdm(all_results, desc="Parsing"):
        if not result or not isinstance(result, dict):
            continue
        
        # UIE çš„ç»“æœæ ¼å¼å¯èƒ½æ˜¯å¤šç§å½¢å¼ï¼Œéœ€è¦çµæ´»å¤„ç†
        # æ–¹å¼1: å¦‚æœ schema æ˜¯ {'äººç‰©': ['å…³ç³»']}ï¼Œç»“æœæ˜¯ {äººç‰©: [{text: ..., å…³ç³»: [{text: ...}]}]}
        if 'äººç‰©' in result:
            persons = result['äººç‰©']
            if isinstance(persons, list):
                for person_info in persons:
                    if isinstance(person_info, dict):
                        person_name = person_info.get('text', '')
                        if not person_name:
                            continue
                        
                        entities.add(person_name)
                        
                        # æå–å…³ç³»
                        relations = person_info.get('å…³ç³»', [])
                        if isinstance(relations, list):
                            for rel_info in relations:
                                if isinstance(rel_info, dict):
                                    rel_type = rel_info.get('text', '')
                                    # å¦‚æœå…³ç³»æŒ‡å‘å¦ä¸€ä¸ªå®ä½“
                                    if 'äººç‰©' in rel_info:
                                        related_persons = rel_info['äººç‰©']
                                        if not isinstance(related_persons, list):
                                            related_persons = [related_persons]
                                        for related_person_info in related_persons:
                                            if isinstance(related_person_info, dict):
                                                related_person = related_person_info.get('text', '')
                                            else:
                                                related_person = str(related_person_info)
                                            
                                            if related_person and related_person != person_name:
                                                entities.add(related_person)
                                                confidence = rel_info.get('probability', 
                                                                         related_person_info.get('probability', 0.0) if isinstance(related_person_info, dict) else 0.0)
                                                relationships.append((
                                                    person_name,
                                                    rel_type if rel_type else 'ç›¸å…³',
                                                    related_person,
                                                    confidence
                                                ))
        
        # æ–¹å¼2: å¦‚æœ schema æ˜¯ {'äººç‰©': ['äººç‰©']}ï¼Œç»“æœæ˜¯å…±ç°å…³ç³»
        # è¿™ç§æ–¹å¼æå–çš„æ˜¯åœ¨åŒä¸€å¥è¯ä¸­å‡ºç°çš„ä¸¤ä¸ªäºº
        # æ³¨æ„ï¼šè¿™ç§æ–¹å¼éœ€è¦é¢å¤–çš„æ–‡æœ¬ä¸Šä¸‹æ–‡ï¼ŒUIE å¯èƒ½ä¸ä¼šç›´æ¥è¿”å›è¿™ç§æ ¼å¼
        
        # æ–¹å¼3: å¤„ç†å…³ç³»æŠ½å–çš„å¦ä¸€ç§æ ¼å¼ - ç›´æ¥çš„ä¸‰å…ƒç»„å½¢å¼
        # å¦‚æœç»“æœåŒ…å« 'relation' å­—æ®µ
        if 'relation' in result:
            for rel_entry in result['relation'] if isinstance(result['relation'], list) else [result['relation']]:
                if isinstance(rel_entry, dict):
                    subject = rel_entry.get('subject', {}).get('text', '') if isinstance(rel_entry.get('subject'), dict) else ''
                    object_entity = rel_entry.get('object', {}).get('text', '') if isinstance(rel_entry.get('object'), dict) else ''
                    predicate = rel_entry.get('predicate', '')
                    if subject and object_entity:
                        entities.add(subject)
                        entities.add(object_entity)
                        relationships.append((
                            subject,
                            predicate if predicate else 'ç›¸å…³',
                            object_entity,
                            rel_entry.get('probability', 0.0)
                        ))
    
    print(f"âœ… æå–å®Œæˆ: å‘ç° {len(entities)} ä¸ªäººç‰©ï¼Œ{len(relationships)} ä¸ªå…³ç³»")
    return relationships, list(entities)


def build_relationship_graph(relationships, entities=None):
    """
    æ„å»ºäººç‰©å…³ç³»å›¾
    
    Args:
        relationships: å…³ç³»åˆ—è¡¨
        entities: å®ä½“åˆ—è¡¨ï¼ˆå¯é€‰ï¼‰
    
    Returns:
        G: NetworkX å›¾å¯¹è±¡
        rel_dict: å…³ç³»å­—å…¸ {(person1, person2): [relations]}
    """
    G = nx.Graph()
    rel_dict = defaultdict(list)
    
    # æ·»åŠ èŠ‚ç‚¹
    if entities:
        for entity in entities:
            G.add_node(entity)
    
    # æ·»åŠ è¾¹å’Œå…³ç³»
    for person1, relation, person2, confidence in relationships:
        if person1 and person2 and person1 != person2:
            G.add_node(person1)
            G.add_node(person2)
            G.add_edge(person1, person2, weight=1.0, relation=relation, confidence=confidence)
            rel_dict[(person1, person2)].append((relation, confidence))
    
    return G, dict(rel_dict)


def plot_relationship_graph(G, relationships, save_path=None, book_name=None):
    """
    ç»˜åˆ¶äººç‰©å…³ç³»å›¾
    
    Args:
        G: NetworkX å›¾å¯¹è±¡
        relationships: å…³ç³»åˆ—è¡¨
        save_path: ä¿å­˜è·¯å¾„
        book_name: ä¹¦ç±åç§°
    """
    if not G.nodes():
        print("âš ï¸ å›¾ä¸­æ²¡æœ‰èŠ‚ç‚¹ï¼Œæ— æ³•ç»˜åˆ¶")
        return
    
    # è®¡ç®—èŠ‚ç‚¹åº¦ï¼ˆè¿æ¥æ•°ï¼‰
    degrees = dict(G.degree())
    
    # é€‰æ‹©ä¸»è¦å­å›¾
    if nx.is_connected(G):
        main_G = G
    else:
        components = list(nx.connected_components(G))
        main_component = max(components, key=len)
        main_G = G.subgraph(main_component).copy()
        print(f"ğŸ“Š ä¸»è¦å­å›¾åŒ…å« {len(main_component)} ä¸ªèŠ‚ç‚¹ï¼ˆå…± {len(G.nodes())} ä¸ªèŠ‚ç‚¹ï¼‰")
    
    # è®¡ç®—èŠ‚ç‚¹å¤§å°
    node_sizes = [degrees.get(node, 1) * 500 for node in main_G.nodes()]
    node_sizes = [max(s, 100) for s in node_sizes]  # æœ€å°å°ºå¯¸
    
    # è®¡ç®—è¾¹çš„æƒé‡
    edge_weights = [G[u][v].get('weight', 1.0) for u, v in main_G.edges()]
    if edge_weights:
        max_weight = max(edge_weights)
        edge_weights = [w * 2.0 / max_weight for w in edge_weights]
    
    # æ ¹æ®èŠ‚ç‚¹æ•°é‡è°ƒæ•´ç”»å¸ƒå¤§å°
    num_nodes = len(main_G.nodes())
    if num_nodes > 50:
        figsize = (32, 24)
        font_size = 6
    elif num_nodes > 30:
        figsize = (24, 20)
        font_size = 8
    else:
        figsize = (18, 15)
        font_size = 10
    
    # ç»˜åˆ¶å›¾å½¢
    plt.figure(figsize=figsize)
    
    # ä½¿ç”¨ spring å¸ƒå±€
    pos = nx.spring_layout(main_G, k=2, iterations=50)
    
    # ç»˜åˆ¶èŠ‚ç‚¹å’Œè¾¹
    nx.draw_networkx_nodes(main_G, pos, node_size=node_sizes, 
                          node_color='lightblue', alpha=0.7, 
                          edgecolors='black', linewidths=0.5)
    nx.draw_networkx_edges(main_G, pos, width=edge_weights, 
                          alpha=0.5, edge_color='gray')
    
    # ç»˜åˆ¶æ ‡ç­¾
    labels = {node: node for node in main_G.nodes()}
    nx.draw_networkx_labels(main_G, pos, labels, font_size=font_size,
                           font_family='sans-serif',
                           bbox=dict(boxstyle='round,pad=0.3', 
                                    facecolor='white', 
                                    edgecolor='none', alpha=0.7))
    
    plt.title(f"äººç‰©å…³ç³»å›¾ - {book_name or 'æœªçŸ¥'} (å…±{num_nodes}ä¸ªäººç‰©)", 
              fontsize=14, pad=20)
    plt.axis('off')
    
    # ä¿å­˜å›¾ç‰‡
    if save_path is None:
        save_path = "output"
    os.makedirs(save_path, exist_ok=True)
    
    if book_name:
        safe_book_name = re.sub(r'[<>:"/\\|?*]', '_', book_name)
        filename = os.path.join(save_path, f"{safe_book_name}_uie_relationship.png")
    else:
        filename = os.path.join(save_path, "uie_relationship.png")
    
    plt.savefig(filename, dpi=150, bbox_inches='tight', 
                facecolor='white', edgecolor='none')
    print(f"âœ… å·²ä¿å­˜å…³ç³»å›¾: {filename}")
    plt.close()


def export_to_excel(relationships, entities, file_path, book_name=None):
    """
    å¯¼å‡ºäººç‰©å…³ç³»åˆ° Excel æ–‡ä»¶
    
    Args:
        relationships: å…³ç³»åˆ—è¡¨
        entities: å®ä½“åˆ—è¡¨
        file_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„
        book_name: ä¹¦ç±åç§°
    """
    # åˆ›å»ºå¤šä¸ªå·¥ä½œè¡¨çš„æ•°æ®
    
    # 1. å…³ç³»è¯¦æƒ…è¡¨
    rel_data = []
    for person1, relation, person2, confidence in relationships:
        rel_data.append({
            'äººç‰©1': person1,
            'å…³ç³»': relation if relation else 'ç›¸å…³',
            'äººç‰©2': person2,
            'ç½®ä¿¡åº¦': f"{confidence:.4f}" if confidence > 0 else "N/A"
        })
    
    # 2. äººç‰©ç»Ÿè®¡è¡¨
    entity_data = []
    entity_counts = defaultdict(int)
    for person1, _, person2, _ in relationships:
        entity_counts[person1] += 1
        entity_counts[person2] += 1
    
    for entity in entities:
        entity_data.append({
            'äººç‰©': entity,
            'å…³ç³»æ•°é‡': entity_counts.get(entity, 0)
        })
    entity_data.sort(key=lambda x: x['å…³ç³»æ•°é‡'], reverse=True)
    
    # 3. å…³ç³»ç±»å‹ç»Ÿè®¡è¡¨
    relation_type_counts = defaultdict(int)
    for _, relation, _, _ in relationships:
        rel_type = relation if relation else 'ç›¸å…³'
        relation_type_counts[rel_type] += 1
    
    rel_type_data = []
    for rel_type, count in sorted(relation_type_counts.items(), 
                                  key=lambda x: x[1], reverse=True):
        rel_type_data.append({
            'å…³ç³»ç±»å‹': rel_type,
            'å‡ºç°æ¬¡æ•°': count
        })
    
    # å†™å…¥ Excel
    with pd.ExcelWriter(file_path, engine='openpyxl') as writer:
        # å…³ç³»è¯¦æƒ…
        if rel_data:
            df_rel = pd.DataFrame(rel_data)
            df_rel.to_excel(writer, sheet_name='å…³ç³»è¯¦æƒ…', index=False)
        
        # äººç‰©ç»Ÿè®¡
        if entity_data:
            df_entity = pd.DataFrame(entity_data)
            df_entity.to_excel(writer, sheet_name='äººç‰©ç»Ÿè®¡', index=False)
        
        # å…³ç³»ç±»å‹ç»Ÿè®¡
        if rel_type_data:
            df_rel_type = pd.DataFrame(rel_type_data)
            df_rel_type.to_excel(writer, sheet_name='å…³ç³»ç±»å‹ç»Ÿè®¡', index=False)
    
    print(f"âœ… å·²å¯¼å‡º Excel æ–‡ä»¶: {file_path}")


def sanitize_filename(filename):
    """æ¸…ç†æ–‡ä»¶å"""
    filename = re.sub(r'[<>:"/\\|?*]', '_', filename)
    filename = filename.strip(' .')
    if len(filename) > 100:
        filename = filename[:100]
    return filename


def main():
    parser = argparse.ArgumentParser(description="ä½¿ç”¨ PaddleNLP UIE æå–å°è¯´äººç‰©å…³ç³»")
    parser.add_argument("--book", default="å†¬æ—¥é‡ç°", type=str,
                       help="ä¹¦çš„åå­—ï¼Œä¸å¸¦åç¼€")
    parser.add_argument("--schema", type=str, default=None,
                       help="è‡ªå®šä¹‰ schemaï¼ˆJSON æ ¼å¼ï¼‰ï¼Œé»˜è®¤ä½¿ç”¨äººç‰©å…³ç³»æŠ½å–")
    parser.add_argument("--batch_size", type=int, default=32,
                       help="æ‰¹å¤„ç†å¤§å°")
    parser.add_argument("--max_length", type=int, default=512,
                       help="æœ€å¤§æ–‡æœ¬é•¿åº¦")
    parser.add_argument("--output", default="output", type=str,
                       help="è¾“å‡ºç›®å½•")
    
    args = parser.parse_args()
    
    if not UIE_AVAILABLE:
        print("âŒ é”™è¯¯: PaddleNLP æœªå®‰è£…")
        print("è¯·è¿è¡Œ: pip install paddlenlp")
        return
    
    # æ–‡ä»¶è·¯å¾„
    fp = f"book/{args.book}.txt"
    if not os.path.exists(fp):
        print(f"âŒ é”™è¯¯: æ–‡ä»¶ä¸å­˜åœ¨: {fp}")
        return
    
    print(f"=====+++=== ä½¿ç”¨ PaddleNLP UIE åˆ†æ: {args.book} ===+++=====")
    
    # è§£æ schemaï¼ˆå¦‚æœæä¾›ï¼‰
    schema = None
    if args.schema:
        import json
        try:
            schema = json.loads(args.schema)
        except:
            print("âš ï¸ Schema è§£æå¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤ schema")
    
    # æå–å…³ç³»
    try:
        relationships, entities = extract_relationships_with_uie(
            fp, 
            schema=schema,
            batch_size=args.batch_size,
            max_length=args.max_length
        )
        
        if not relationships:
            print("âš ï¸ æœªæå–åˆ°ä»»ä½•å…³ç³»ï¼Œå¯èƒ½éœ€è¦è°ƒæ•´ schema æˆ–æ–‡æœ¬æ ¼å¼")
            return
        
        # æ„å»ºå…³ç³»å›¾
        print("ğŸ“Š æ­£åœ¨æ„å»ºå…³ç³»å›¾...")
        G, rel_dict = build_relationship_graph(relationships, entities)
        
        # ç»˜åˆ¶å…³ç³»å›¾
        print("ğŸ¨ æ­£åœ¨ç»˜åˆ¶å…³ç³»å›¾...")
        os.makedirs(args.output, exist_ok=True)
        plot_relationship_graph(G, relationships, 
                               save_path=args.output, 
                               book_name=args.book)
        
        # å¯¼å‡º Excel
        print("ğŸ“ æ­£åœ¨å¯¼å‡º Excel æ–‡ä»¶...")
        excel_path = os.path.join(args.output, 
                                 f"{sanitize_filename(args.book)}_äººç‰©å…³ç³».xlsx")
        export_to_excel(relationships, entities, excel_path, book_name=args.book)
        
        print("="*50)
        print("âœ… å¤„ç†å®Œæˆï¼")
        print(f"   - æå–åˆ° {len(entities)} ä¸ªäººç‰©")
        print(f"   - æå–åˆ° {len(relationships)} ä¸ªå…³ç³»")
        print(f"   - å…³ç³»å›¾å·²ä¿å­˜åˆ°: {args.output}")
        print(f"   - Excel æ–‡ä»¶å·²ä¿å­˜åˆ°: {excel_path}")
        print("="*50)
        
    except Exception as e:
        print(f"âŒ å¤„ç†è¿‡ç¨‹ä¸­å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()

